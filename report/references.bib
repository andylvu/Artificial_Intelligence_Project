
@article{mathews_partition_1896,
  title    = {On the {Partition} of {Numbers}},
  volume   = {s1-28},
  issn     = {00246115},
  url      = {http://doi.wiley.com/10.1112/plms/s1-28.1.486},
  doi      = {10.1112/plms/s1-28.1.486},
  language = {en},
  number   = {1},
  urldate  = {2022-03-23},
  journal  = {Proceedings of the London Mathematical Society},
  author   = {Mathews, G. B.},
  month    = nov,
  year     = {1896},
  pages    = {486--490}
}

@misc{agha_binary_2021,
  title    = {The {Binary} {Multidimensional} {Knapsack} {Problem} ({MKP})},
  url      = {https://towardsdatascience.com/the-binary-multidimensional-knapsack-problem-mkp-2559745f5fde},
  abstract = {Overview, benchmarks and code},
  language = {en},
  urldate  = {2022-03-25},
  journal  = {Medium},
  author   = {Agha, Mohammed},
  month    = jul,
  year     = {2021}
}

@article{nomer_neural_2020,
  title      = {Neural {Knapsack}: {A} {Neural} {Network} {Based} {Solver} for the {Knapsack} {Problem}},
  volume     = {8},
  issn       = {2169-3536},
  shorttitle = {Neural {Knapsack}},
  doi        = {10.1109/ACCESS.2020.3044005},
  abstract   = {This paper introduces a heuristic solver based on neural networks and deep learning for the knapsack problem. The solver is inspired by mechanisms and strategies used by both algorithmic solvers and humans. The neural model of the solver is based on introducing several biases in the architecture. We introduce a stored memory of vectors that holds up items representations and their relationship to the capacity of the knapsack and a module that allows the solver to access all the previous outputs it generated. The solver is trained and tested on synthetic datasets that represent a variety of instance types with different complexities. The solver neural model capabilities to generalize were tested on instances with up to 200 items, the model succeed to obtain near optimal solutions better than the greedy algorithm for instances in which there exists a correlation between items values and weights. The results also show that the capacity of the knapsack has a role in learning useful representations for each item in an instance and for the instance itself. Although the proposed solver may be not superior to other solvers, the results described here are insights for how the connection between combinatorial optimization, machine learning, and cognitive science could serve a great purpose in the operation research field. The goal of this work is not to design a state of the art solver, rather it full-fills some of the holes in the recent line of research that incorporates learning in combinatorial optimization problems.},
  journal    = {IEEE Access},
  author     = {Nomer, Hazem A. A. and Alnowibet, Khalid Abdulaziz and Elsayed, Ashraf and Mohamed, Ali Wagdy},
  year       = {2020},
  keywords   = {Optimization, Neural networks, Task analysis, Approximation algorithms, Search problems, Recurrent neural networks, Operations research, Knapsack, neural networks, machine learning, combinatorial optimization},
  pages      = {224200--224210}
}

@misc{noauthor_pdf_nodate,
  title    = {({PDF}) {A} {Hybrid} {Genetic} {Algorithm} for the {Multidimensional} {Knapsack} {Problem}},
  url      = {https://www.researchgate.net/publication/228939007_A_Hybrid_Genetic_Algorithm_for_the_Multidimensional_Knapsack_Problem},
  abstract = {PDF {\textbar} During the last two decades solving combinatorial optimization problems, using genetic algorithms (GA), has attracted the attention of many... {\textbar} Find, read and cite all the research you need on ResearchGate},
  language = {en},
  urldate  = {2022-03-25},
  journal  = {ResearchGate}
}