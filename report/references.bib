
@article{mathews_partition_1896,
  title    = {On the {Partition} of {Numbers}},
  volume   = {s1-28},
  issn     = {00246115},
  url      = {http://doi.wiley.com/10.1112/plms/s1-28.1.486},
  doi      = {10.1112/plms/s1-28.1.486},
  language = {en},
  number   = {1},
  urldate  = {2022-03-23},
  journal  = {Proceedings of the London Mathematical Society},
  author   = {Mathews, G. B.},
  month    = nov,
  year     = {1896},
  pages    = {486--490}
}

@misc{agha_binary_2021,
  title    = {The {Binary} {Multidimensional} {Knapsack} {Problem} ({MKP})},
  url      = {https://towardsdatascience.com/the-binary-multidimensional-knapsack-problem-mkp-2559745f5fde},
  abstract = {Overview, benchmarks and code},
  language = {en},
  urldate  = {2022-03-25},
  journal  = {Medium},
  author   = {Agha, Mohammed},
  month    = jul,
  year     = {2021}
}

@article{nomer_neural_2020,
  title      = {Neural {Knapsack}: {A} {Neural} {Network} {Based} {Solver} for the {Knapsack} {Problem}},
  volume     = {8},
  issn       = {2169-3536},
  shorttitle = {Neural {Knapsack}},
  doi        = {10.1109/ACCESS.2020.3044005},
  abstract   = {This paper introduces a heuristic solver based on neural networks and deep learning for the knapsack problem. The solver is inspired by mechanisms and strategies used by both algorithmic solvers and humans. The neural model of the solver is based on introducing several biases in the architecture. We introduce a stored memory of vectors that holds up items representations and their relationship to the capacity of the knapsack and a module that allows the solver to access all the previous outputs it generated. The solver is trained and tested on synthetic datasets that represent a variety of instance types with different complexities. The solver neural model capabilities to generalize were tested on instances with up to 200 items, the model succeed to obtain near optimal solutions better than the greedy algorithm for instances in which there exists a correlation between items values and weights. The results also show that the capacity of the knapsack has a role in learning useful representations for each item in an instance and for the instance itself. Although the proposed solver may be not superior to other solvers, the results described here are insights for how the connection between combinatorial optimization, machine learning, and cognitive science could serve a great purpose in the operation research field. The goal of this work is not to design a state of the art solver, rather it full-fills some of the holes in the recent line of research that incorporates learning in combinatorial optimization problems.},
  journal    = {IEEE Access},
  author     = {Nomer, Hazem A. A. and Alnowibet, Khalid Abdulaziz and Elsayed, Ashraf and Mohamed, Ali Wagdy},
  year       = {2020},
  keywords   = {Optimization, Neural networks, Task analysis, Approximation algorithms, Search problems, Recurrent neural networks, Operations research, Knapsack, neural networks, machine learning, combinatorial optimization},
  pages      = {224200--224210}
}

@article{djannaty_hybrid_2008,
  author  = {Djannaty, Farhad and Doustdargholi, Saber},
  year    = {2008},
  month   = {01},
  pages   = {443-456},
  title   = {A Hybrid Genetic Algorithm for the Multidimensional Knapsack Problem},
  volume  = {3},
  journal = {Int. J. Contemp. Math. Sciences}
}

@article{caserta_robust_2019,
  title    = {The robust multiple-choice multidimensional knapsack problem},
  volume   = {86},
  issn     = {0305-0483},
  url      = {https://www.sciencedirect.com/science/article/pii/S0305048317305777},
  doi      = {10.1016/j.omega.2018.06.014},
  abstract = {The multiple-choice multidimensional knapsack problem (MMKP) assumes n sets composed of mutually exclusive items. The goal is to select exactly one item per set, maximizing the overall utility, without violating a family of knapsack constraints. Motivated by recent applications of the MMKP to complex system reliability and quality of service management problems, we propose a robust version. More specifically, we relinquish the assumption that the problem parameters are deterministically known by limiting their values to a pre-specified uncertainty set. Depending on the structure of the variance−covariance matrix used to model the uncertainty, we identify four different cases, leading to robust formulations characterized by second order cone programs. We show how each of these programs is transformed into an equivalent linear program, implying that the use of a robust formulation for the MMKP comes with no extra computational complexity. Finally, using a novel matheuristic designed for the MMKP, we shed lights on the trade-off between the “price of robustness,” i.e., how much worse the objective function value of a robust solution is, compared with the deterministic one, and the “reliability,” i.e., the probability that a robust solution will lead to a feasible scenario for an arbitrary realization of the uncertain parameters.},
  language = {en},
  urldate  = {2022-03-25},
  journal  = {Omega},
  author   = {Caserta, Marco and Voß, Stefan},
  month    = jul,
  year     = {2019},
  keywords = {Robust optimization, Knapsack problems, Mixed-integer programming},
  pages    = {16--27}
}

@article{mansi_hybrid_2013,
  title    = {A hybrid heuristic for the multiple choice multidimensional knapsack problem},
  volume   = {45},
  issn     = {0305-215X},
  url      = {https://ui.adsabs.harvard.edu/abs/2013EnOp...45..983M},
  doi      = {10.1080/0305215X.2012.717072},
  abstract = {In this article, a new solution approach for the multiple choice multidimensional knapsack problem is described. The problem is a variant of the multidimensional knapsack problem where items are divided into classes, and exactly one item per class has to be chosen. Both problems are NP-hard. However, the multiple choice multidimensional knapsack problem appears to be more difficult to solve in part because of its choice constraints. Many real applications lead to very large scale multiple choice multidimensional knapsack problems that can hardly be addressed using exact algorithms. A new hybrid heuristic is proposed that embeds several new procedures for this problem. The approach is based on the resolution of linear programming relaxations of the problem and reduced problems that are obtained by fixing some variables of the problem. The solutions of these problems are used to update the global lower and upper bounds for the optimal solution value. A new strategy for defining the reduced problems is explored, together with a new family of cuts and a reformulation procedure that is used at each iteration to improve the performance of the heuristic. An extensive set of computational experiments is reported for benchmark instances from the literature and for a large set of hard instances generated randomly. The results show that the approach outperforms other state-of-the-art methods described so far, providing the best known solution for a significant number of benchmark instances.},
  urldate  = {2022-03-25},
  journal  = {Engineering Optimization},
  author   = {Mansi, Raïd and Alves, Cláudio and Valério de Carvalho, J. M. and Hanafi, Saïd},
  month    = aug,
  year     = {2013},
  note     = {ADS Bibcode: 2013EnOp...45..983M},
  keywords = {hybrid heuristics, multiple choice knapsack problem, integer linear programming, relaxations},
  pages    = {983--1004}
}
